{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f164af-648b-463f-892a-c377461752f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What are the key features of the wine quality data set? Discuss the importance of each feature in\n",
    "predicting the quality of wine.\n",
    "The wine quality dataset typically contains features such as:\n",
    "\n",
    "Fixed Acidity: The amount of fixed acids (e.g., tartaric acid). It affects the taste and stability of wine. Higher acidity generally correlates with a sharper taste.\n",
    "\n",
    "Volatile Acidity: The amount of volatile acids (e.g., acetic acid). High levels can lead to an unpleasant vinegar-like taste.\n",
    "\n",
    "Citric Acid: It adds a citrus flavor and can balance the wine’s acidity. It’s important for flavor and stability.\n",
    "\n",
    "Residual Sugar: The amount of sugar left after fermentation. It affects the sweetness and body of the wine.\n",
    "Q2. How did you handle missing data in the wine quality data set during the feature engineering process?\n",
    "Discuss the advantages and disadvantages of different imputation techniques.\n",
    "Imputation Techniques:\n",
    "\n",
    "Mean/Median Imputation: Replace missing values with the mean or median of the feature. This is simple but can distort the distribution.\n",
    "\n",
    "Advantages: Easy to implement.\n",
    "Disadvantages: Can reduce variance and may not be suitable for skewed distributions.\n",
    "Mode Imputation: For categorical data, replace missing values with the most frequent category.\n",
    "\n",
    "Advantages: Maintains the distribution of categorical features.\n",
    "Disadvantages: May not capture the underlying data patterns.\n",
    "K-Nearest Neighbors (KNN) Imputation: Replace missing values based on the values from the nearest neighbors.\n",
    "\n",
    "Advantages: Can capture relationships between features.\n",
    "Disadvantages: Computationally intensive and may not work well for high-dimensional data.\n",
    "Q3. What are the key factors that affect students' performance in exams? How would you go about\n",
    "analyzing these factors using statistical techniques?\n",
    "Key Factors:\n",
    "\n",
    "Study Time: Amount of time spent studying.\n",
    "Previous Grades: Performance in previous exams or subjects.\n",
    "Parental Education: Education level of parents.\n",
    "Attendance: Number of classes attended.\n",
    "Extracurricular Activities: Participation in activities outside the academic curriculum.\n",
    "Sleep Duration: Average amount of sleep per night.\n",
    "Socioeconomic Status: Economic background of the student.\n",
    "Q4. Describe the process of feature engineering in the context of the student performance data set. How\n",
    "did you select and transform the variables for your model?\n",
    "Process:\n",
    "\n",
    "Selection: Identify relevant features based on domain knowledge and data exploration.\n",
    "Transformation:\n",
    "Normalization/Standardization: Ensure features are on a comparable scale.\n",
    "Encoding: Convert categorical variables into numerical values (e.g., one-hot encoding).\n",
    "Aggregation: Create new features by aggregating or combining existing ones (e.g., total study time across subjects).\n",
    "Selection: Use techniques like feature importance from models or correlation analysis to select the most impactful features.\n",
    "Q5. Load the wine quality data set and perform exploratory data analysis (EDA) to identify the distribution\n",
    "of each feature. Which feature(s) exhibit non-normality, and what transformations could be applied to\n",
    "these features to improve normality?\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('winequality-red.csv')\n",
    "\n",
    "# Plot distributions\n",
    "for column in df.columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(df[column], kde=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.show()\n",
    "\n",
    "Q6. Using the wine quality data set, perform principal component analysis (PCA) to reduce the number of\n",
    "features. What is the minimum number of principal components required to explain 90% of the variance in\n",
    "the data?\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('winequality-red.csv')\n",
    "\n",
    "# Drop the target variable for PCA\n",
    "X = df.drop('quality', axis=1)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Explained variance\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_components = np.argmax(explained_variance >= 0.90) + 1\n",
    "\n",
    "print(f\"Minimum number of principal components required to explain 90% of the variance: {n_components}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
