{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f8d02-59e9-484d-9c27-0ea9356ef20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is anomaly detection and what is its purpose?\n",
    "Anomaly detection is the process of identifying unusual patterns, observations, or data points that do not conform to the expected behavior of the data. These unusual patterns are known as anomalies, outliers, or exceptions.\n",
    "\n",
    "Purpose:\n",
    "\n",
    "Detecting fraud or malicious activities (e.g., in financial transactions or cybersecurity).\n",
    "Identifying defects in manufacturing processes.\n",
    "Monitoring health status in medical diagnostics.\n",
    "Detecting faults in system operations or equipment.\n",
    "Q2. What are the key challenges in anomaly detection?\n",
    "Key Challenges:\n",
    "\n",
    "Imbalanced Data: Anomalies are often rare, leading to a significant class imbalance.\n",
    "Variety of Anomalies: Anomalies can vary widely in their nature and context.\n",
    "High Dimensionality: High-dimensional data can make it difficult to detect anomalies.\n",
    "Dynamic Data: In some applications, the data distribution may change over time.\n",
    "Noise: Distinguishing between noise and actual anomalies can be challenging.\n",
    "Scalability: Efficiently processing large datasets to identify anomalies.\n",
    "Interpretability: Explaining why a particular data point is considered an anomaly.\n",
    "Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "Unsupervised Anomaly Detection:\n",
    "\n",
    "No labeled training data is available.\n",
    "Relies on the assumption that anomalies are rare and different from the majority of the data.\n",
    "Techniques include clustering, density estimation, and distance-based methods.\n",
    "Supervised Anomaly Detection:\n",
    "\n",
    "Requires labeled training data with normal and anomalous instances.\n",
    "Uses classification algorithms to learn patterns and identify anomalies.\n",
    "Techniques include support vector machines, neural networks, and decision trees.\n",
    "Q4. What are the main categories of anomaly detection algorithms?\n",
    "Main Categories:\n",
    "\n",
    "Statistical Methods:\n",
    "\n",
    "Based on probability distributions and statistical tests.\n",
    "Examples: Z-score, Grubbs' test.\n",
    "Machine Learning Methods:\n",
    "\n",
    "Supervised and unsupervised learning techniques.\n",
    "Examples: Isolation Forest, Support Vector Machines, Neural Networks.\n",
    "Clustering Methods:\n",
    "\n",
    "Identify anomalies as points that do not belong to any cluster or belong to small/sparse clusters.\n",
    "Examples: DBSCAN, K-means.\n",
    "Distance-Based Methods:\n",
    "\n",
    "Identify anomalies based on their distance from other points.\n",
    "Examples: K-Nearest Neighbors (KNN), Local Outlier Factor (LOF).\n",
    "Density-Based Methods:\n",
    "\n",
    "Identify anomalies based on the density of data points in the vicinity.\n",
    "Examples: LOF, Kernel Density Estimation.\n",
    "Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "Main Assumptions:\n",
    "\n",
    "Homogeneity: Normal data points are clustered closely together.\n",
    "Sparsity: Anomalies are far away from the dense regions of normal data points.\n",
    "Consistency: Distance metrics are consistent and reliable for differentiating between normal and anomalous points.\n",
    "Q6. How does the LOF algorithm compute anomaly scores?\n",
    "The Local Outlier Factor (LOF) algorithm computes anomaly scores by comparing the local density of a data point to the local densities of its neighbors.\n",
    "\n",
    "Steps:\n",
    "\n",
    "Calculate k-distance: For each point, find the distance to its k-th nearest neighbor.\n",
    "Calculate local reachability density (LRD): For each point, compute the average reachability distance from its neighbors.\n",
    "Compute LOF score: For each point, the LOF score is the average ratio of the LRDs of its neighbors to its own LRD.\n",
    "Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "Key Parameters:\n",
    "\n",
    "n_estimators: The number of trees in the forest. More trees can improve the robustness of the model.\n",
    "max_samples: The number of samples to draw to train each tree. A smaller subset of the dataset.\n",
    "contamination: The proportion of outliers in the data. Used to set the threshold for identifying anomalies.\n",
    "max_features: The number of features to consider when looking for the best split.\n",
    "Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score\n",
    "using KNN with K=10?\n",
    "In KNN-based anomaly detection, the anomaly score can be interpreted based on the number of neighbors within a specified radius. If a data point has only 2 neighbors of the same class within a radius of 0.5 but K=10:\n",
    "\n",
    "AnomalyÂ Score\n",
    "=\n",
    "1\n",
    "âˆ’\n",
    "NumberÂ ofÂ NeighborsÂ withinÂ radius\n",
    "ğ¾\n",
    "=\n",
    "1\n",
    "âˆ’\n",
    "2\n",
    "10\n",
    "=\n",
    "0.8\n",
    "AnomalyÂ Score=1âˆ’ \n",
    "K\n",
    "NumberÂ ofÂ NeighborsÂ withinÂ radius\n",
    "â€‹\n",
    " =1âˆ’ \n",
    "10\n",
    "2\n",
    "â€‹\n",
    " =0.8\n",
    "\n",
    "This indicates that the data point is considered anomalous since it has significantly fewer neighbors within the radius compared to the expected number.\n",
    "Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the\n",
    "anomaly score for a data point that has an average path length of 5.0 compared to the average path\n",
    "length of the trees?\n",
    "In the Isolation Forest algorithm, the anomaly score is calculated based on the average path length of a data point.\n",
    "\n",
    "Average Path Length Calculation:\n",
    "ğ‘\n",
    "(\n",
    "ğ‘›\n",
    ")\n",
    "=\n",
    "2\n",
    "(\n",
    "ln\n",
    "â¡\n",
    "(\n",
    "ğ‘›\n",
    "âˆ’\n",
    "1\n",
    ")\n",
    "+\n",
    "ğ›¾\n",
    ")\n",
    "âˆ’\n",
    "2\n",
    "(\n",
    "ğ‘›\n",
    "âˆ’\n",
    "1\n",
    ")\n",
    "ğ‘›\n",
    "c(n)=2(ln(nâˆ’1)+Î³)âˆ’ \n",
    "n\n",
    "2(nâˆ’1)\n",
    "â€‹\n",
    " \n",
    "where \n",
    "ğ‘›\n",
    "n is the number of data points, and \n",
    "ğ›¾\n",
    "Î³ is the Euler-Mascheroni constant (approximately 0.577).\n",
    "\n",
    "For \n",
    "ğ‘›\n",
    "=\n",
    "3000\n",
    "n=3000:\n",
    "ğ‘\n",
    "(\n",
    "3000\n",
    ")\n",
    "=\n",
    "2\n",
    "(\n",
    "ln\n",
    "â¡\n",
    "(\n",
    "2999\n",
    ")\n",
    "+\n",
    "0.577\n",
    ")\n",
    "âˆ’\n",
    "2\n",
    "(\n",
    "2999\n",
    ")\n",
    "3000\n",
    "c(3000)=2(ln(2999)+0.577)âˆ’ \n",
    "3000\n",
    "2(2999)\n",
    "â€‹\n",
    " \n",
    "ğ‘\n",
    "(\n",
    "3000\n",
    ")\n",
    "â‰ˆ\n",
    "2\n",
    "(\n",
    "ln\n",
    "â¡\n",
    "(\n",
    "2999\n",
    ")\n",
    "+\n",
    "0.577\n",
    ")\n",
    "âˆ’\n",
    "1.999\n",
    "c(3000)â‰ˆ2(ln(2999)+0.577)âˆ’1.999\n",
    "ğ‘\n",
    "(\n",
    "3000\n",
    ")\n",
    "â‰ˆ\n",
    "2\n",
    "(\n",
    "8.006\n",
    "+\n",
    "0.577\n",
    ")\n",
    "âˆ’\n",
    "1.999\n",
    "c(3000)â‰ˆ2(8.006+0.577)âˆ’1.999\n",
    "ğ‘\n",
    "(\n",
    "3000\n",
    ")\n",
    "â‰ˆ\n",
    "2\n",
    "(\n",
    "8.583\n",
    ")\n",
    "âˆ’\n",
    "1.999\n",
    "c(3000)â‰ˆ2(8.583)âˆ’1.999\n",
    "ğ‘\n",
    "(\n",
    "3000\n",
    ")\n",
    "â‰ˆ\n",
    "17.166\n",
    "âˆ’\n",
    "1.999\n",
    "â‰ˆ\n",
    "15.167\n",
    "c(3000)â‰ˆ17.166âˆ’1.999â‰ˆ15.167\n",
    "\n",
    "Anomaly Score Calculation:\n",
    "AnomalyÂ Score\n",
    "=\n",
    "2\n",
    "âˆ’\n",
    "AverageÂ PathÂ Length\n",
    "ğ‘\n",
    "(\n",
    "ğ‘›\n",
    ")\n",
    "AnomalyÂ Score=2 \n",
    "âˆ’ \n",
    "c(n)\n",
    "AverageÂ PathÂ Length\n",
    "â€‹\n",
    " \n",
    " \n",
    "AnomalyÂ Score\n",
    "=\n",
    "2\n",
    "âˆ’\n",
    "5.0\n",
    "15.167\n",
    "AnomalyÂ Score=2 \n",
    "âˆ’ \n",
    "15.167\n",
    "5.0\n",
    "â€‹\n",
    " \n",
    " \n",
    "AnomalyÂ Score\n",
    "â‰ˆ\n",
    "2\n",
    "âˆ’\n",
    "0.329\n",
    "â‰ˆ\n",
    "0.800\n",
    "AnomalyÂ Scoreâ‰ˆ2 \n",
    "âˆ’0.329\n",
    " â‰ˆ0.800\n",
    "\n",
    "An anomaly score close to 1 indicates a high likelihood of being an anomaly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
