{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a988795-91c3-4b7a-bcad-a6a88695fc89",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 49) (1027269016.py, line 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 49\u001b[0;36m\u001b[0m\n\u001b[0;31m    Variance: Error due to the model's sensitivity to small fluctuations in the training data (overfitting). High variance leads to models that are too complex.\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 49)\n"
     ]
    }
   ],
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
    "can they be mitigated?\n",
    "Overfitting:\n",
    "\n",
    "Definition: When a model learns the training data too well, capturing noise and details that do not generalize to new data.\n",
    "Consequences: The model performs well on training data but poorly on unseen data.\n",
    "Mitigation:\n",
    "Use more training data.\n",
    "Apply regularization techniques (e.g., L1, L2 regularization).\n",
    "Use simpler models.\n",
    "Perform cross-validation.\n",
    "Prune decision trees or use dropout in neural networks.\n",
    "Underfitting:\n",
    "\n",
    "Definition: When a model is too simple to capture the underlying patterns in the data.\n",
    "Consequences: The model performs poorly on both training and test data.\n",
    "Mitigation:\n",
    "Use more complex models.\n",
    "Provide more features to the model.\n",
    "Reduce regularization.\n",
    "Increase training duration.\n",
    "\n",
    "Q2: How can we reduce overfitting? Explain in brief.\n",
    "Methods to Reduce Overfitting:\n",
    "\n",
    "Cross-Validation: Using techniques like k-fold cross-validation to ensure the model generalizes well.\n",
    "Regularization: Adding penalty terms to the loss function, such as L1 (lasso) and L2 (ridge) regularization.\n",
    "Pruning: Reducing the complexity of decision trees by removing parts of the tree that provide little power.\n",
    "Dropout: In neural networks, randomly dropping units during training to prevent over-reliance on specific paths.\n",
    "Early Stopping: Halting training when performance on a validation set starts to degrade.\n",
    "Simpler Models: Using less complex models that are less likely to overfit.\n",
    "\n",
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n",
    "Underfitting:\n",
    "\n",
    "Definition: When a model is too simplistic to capture the underlying structure of the data, resulting in poor performance.\n",
    "Scenarios Where Underfitting Can Occur:\n",
    "\n",
    "Insufficient Training: The model has not been trained long enough to learn patterns in the data.\n",
    "Over-Simplified Model: Using a model that is too simple, like a linear model for non-linear data.\n",
    "Too Much Regularization: Excessive regularization can force the model to be too simple.\n",
    "Inadequate Features: Not providing enough features or using features that do not capture the complexity of the data.\n",
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?\n",
    "\n",
    "Bias-Variance Tradeoff:\n",
    "\n",
    "Bias: Error due to overly simplistic assumptions in the model (underfitting). High bias leads to systematic errors.\n",
    "Variance: Error due to the model's sensitivity to small fluctuations in the training data (overfitting). High variance leads to models that are too complex.\n",
    "Relationship and Effect:\n",
    "\n",
    "High Bias: Low variance, high bias models are consistent but inaccurate on both training and test data.\n",
    "High Variance: Low bias, high variance models are accurate on training data but inconsistent on test data.\n",
    "Optimal Balance: Achieving a balance where the model has low bias and low variance, leading to good generalization.\n",
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?\n",
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?\n",
    "Methods for Detecting Overfitting and Underfitting:\n",
    "\n",
    "Train-Test Split: Evaluate model performance on both training and test datasets.\n",
    "Cross-Validation: Use techniques like k-fold cross-validation to assess model generalization.\n",
    "Learning Curves: Plot training and validation error as a function of the number of training examples.\n",
    "Overfitting: Low training error but high validation error.\n",
    "Underfitting: High training error and high validation error.\n",
    "Determining Overfitting or Underfitting:\n",
    "\n",
    "Overfitting: Model performs well on training data but poorly on test data.\n",
    "Underfitting: Model performs poorly on both training and test data.\n",
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work.\n",
    "Regularization:\n",
    "\n",
    "Definition: Techniques to add constraints to a model to prevent it from fitting the noise in the training data (overfitting).\n",
    "Common Techniques:\n",
    "\n",
    "L1 Regularization (Lasso):\n",
    "L2 Regularization (Ridge)\n",
    " Elastic Net:\n",
    "    \\ Dropout:\n",
    "            Early Stopping:\n",
    "                Regularization helps to prevent overfitting by penalizing complexity,\n",
    "                leading to simpler models that generalize better to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730cf26-c36f-4e7d-b49b-c5843cd85bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1fccda-fd67-4826-af71-aaa1128c2efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
