{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e98e69-85fb-4c48-9300-eb1df2977908",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the main difference between the Euclidean distance metric and the Manhattan distance\n",
    "metric in KNN? How might this difference affect the performance of a KNN classifier or regressor?\n",
    "Euclidean Distance: Measures the straight-line distance between two points in Euclidean space. It is calculated as:\n",
    "    Manhattan Distance: Measures the distance between two points along the axes at right angles (the sum of the absolute differences of their coordinates). It is calculated as:\n",
    "Q2. How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be\n",
    "used to determine the optimal k value?\n",
    "Choosing the optimal value of \n",
    "ùëò\n",
    "k can be done using several techniques:\n",
    "\n",
    "Cross-Validation: Perform k-fold cross-validation on the training data to evaluate different values of \n",
    "ùëò\n",
    "k. Select the \n",
    "ùëò\n",
    "k that minimizes the validation error.\n",
    "Grid Search: Create a grid of \n",
    "ùëò\n",
    "k values and use cross-validation to find the best \n",
    "ùëò\n",
    "k.\n",
    "Rule of Thumb: Use the square root of the number of training samples (\n",
    "ùëõ\n",
    "n\n",
    "‚Äã\n",
    " ) as a starting point and adjust based on performance.\n",
    "Elbow Method: Plot the error rate as a function of \n",
    "ùëò\n",
    "k and look for an \"elbow\" point where the rate of error reduction slows down.\n",
    "Q3. How does the choice of distance metric affect the performance of a KNN classifier or regressor? In\n",
    "what situations might you choose one distance metric over the other?\n",
    "The choice of distance metric affects how distances between points are computed, which in turn influences the identification of nearest neighbors and the model's predictions.\n",
    "\n",
    "Euclidean Distance: Choose when the data is compact and features are on similar scales. It works well for spherical clusters.\n",
    "Manhattan Distance: Prefer when dealing with high-dimensional data, sparse data, or when features are on different scales. It is more robust to outliers.\n",
    "Situational Choice:\n",
    "\n",
    "Image Recognition: Euclidean distance is often used due to the spatial nature of the data.\n",
    "Text Data: Manhattan distance might be preferred for text data represented as sparse vectors (e.g., bag-of-words model).\n",
    "Q4. What are some common hyperparameters in KNN classifiers and regressors, and how do they affect\n",
    "the performance of the model? How might you go about tuning these hyperparameters to improve\n",
    "model performance?\n",
    "Common Hyperparameters:\n",
    "\n",
    "Number of Neighbors (k): Determines the number of nearest neighbors to consider. A small \n",
    "ùëò\n",
    "k can lead to overfitting, while a large \n",
    "ùëò\n",
    "k can lead to underfitting.\n",
    "Distance Metric: Choice of Euclidean, Manhattan, or other distance metrics affects how distances are computed and neighbors are identified.\n",
    "Weighting Function: Uniform weighting treats all neighbors equally, while distance weighting gives more importance to closer neighbors.\n",
    "Tuning Techniques:\n",
    "\n",
    "Grid Search: Explore combinations of hyperparameters using cross-validation to find the best settings.\n",
    "Random Search: Randomly sample hyperparameter combinations and evaluate performance.\n",
    "Bayesian Optimization: Use probabilistic models to find the optimal hyperparameters efficiently.\n",
    "Q5. How does the size of the training set affect the performance of a KNN classifier or regressor? What\n",
    "techniques can be used to optimize the size of the training set?\n",
    "The size of the training set can significantly impact the performance of a KNN model:\n",
    "\n",
    "Larger Training Set: Generally improves the model's ability to generalize, but increases computational complexity.\n",
    "Smaller Training Set: Reduces computation time but may lead to overfitting or underfitting.\n",
    "Techniques to Optimize Training Set Size:\n",
    "\n",
    "Sampling: Use techniques like stratified sampling to maintain a representative subset of the data.\n",
    "Dimensionality Reduction: Apply PCA, LDA, or other techniques to reduce the number of features while retaining essential information.\n",
    "Data Augmentation: Generate synthetic data to increase the size of the training set when dealing with limited data.\n",
    "Q6. What are some potential drawbacks of using KNN as a classifier or regressor? How might you\n",
    "overcome these drawbacks to improve the performance of the model?\n",
    "Drawbacks:\n",
    "\n",
    "Computational Complexity: High memory and computation requirements during prediction, especially with large datasets.\n",
    "Curse of Dimensionality: Performance decreases with increasing dimensionality.\n",
    "Sensitivity to Noise: Outliers and noisy data can adversely affect performance.\n",
    "Feature Scaling: Requires careful scaling of features to avoid bias in distance calculations.\n",
    "Overcoming Drawbacks:\n",
    "\n",
    "Efficient Data Structures: Use KD-trees, Ball-trees, or approximate nearest neighbor algorithms to speed up neighbor searches.\n",
    "Dimensionality Reduction: Reduce the number of features to mitigate the curse of dimensionality.\n",
    "Feature Scaling: Standardize or normalize features to ensure equal contribution to distance metrics.\n",
    "Noise Reduction: Use techniques like data cleaning or robust distance metrics to handle noise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
