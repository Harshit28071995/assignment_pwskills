{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdae869-a8b1-440a-b005-1994d33e4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it\n",
    "represent?\n",
    "Concept:\n",
    "\n",
    "R-squared (Coefficient of Determination) measures the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "Q2. Define adjusted R-squared and explain how it differs from the regular R-squared.\n",
    "Adjusted R-squared adjusts the R-squared value for the number of predictors in the model. It accounts for the number of predictors relative to the number of data points.\n",
    "Q3. When is it more appropriate to use adjusted R-squared?\n",
    "Adjusted R-squared is more appropriate when comparing models with different numbers of predictors. It provides a more accurate measure of model performance by accounting for the number of predictors and avoiding the inflation of R-squared due to overfitting.\n",
    "Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics\n",
    "calculated, and what do they represent?\n",
    "Mean Squared Error (MSE): Represents: The average of the squared differences between actual and predicted values. Sensitive to outliers.\n",
    "Root Mean Squared Error (RMSE): Represents: The square root of MSE. Provides an error measure in the same units as the target variable. Sensitive to outliers.\n",
    "Mean Absolute Error (MAE): Represents: The average of the absolute differences between actual and predicted values. Less sensitive to outliers compared to MSE and RMSE.\n",
    "Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in\n",
    "regression analysis.\n",
    "Advantages:\n",
    "\n",
    "RMSE: Useful when larger errors are particularly undesirable. Provides error magnitude in original units.\n",
    "MSE: Easier to work with mathematically and emphasizes larger errors.\n",
    "MAE: Provides a direct measure of average error magnitude and is less sensitive to outliers.\n",
    "Disadvantages:\n",
    "\n",
    "RMSE/MSE: Sensitive to outliers, which can distort the metric.\n",
    "MAE: Does not penalize large errors as much as RMSE, so it may be less useful when large errors are particularly harmful.\n",
    "Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is\n",
    "it more appropriate to use?\n",
    "Concept:\n",
    "\n",
    "Lasso Regularization (Least Absolute Shrinkage and Selection Operator) adds a penalty equal to the absolute value of the magnitude of coefficients to the loss function.\n",
    "Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an\n",
    "example to illustrate.\n",
    "Concept:\n",
    "\n",
    "Regularized Linear Models (like Lasso and Ridge) add a penalty term to the cost function to prevent overfitting by discouraging overly complex models.\n",
    "Example:\n",
    "\n",
    "Suppose you have a model with many features, and it performs well on the training data but poorly on the validation data. Regularization can reduce the magnitude of the coefficients, simplify the model, and improve performance on unseen data.\n",
    "Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best\n",
    "choice for regression analysis.\n",
    "Limitations:\n",
    "\n",
    "Regularization Bias: Regularization introduces bias by shrinking coefficients, which can sometimes lead to underfitting.\n",
    "Choice of Regularization Parameter: Choosing the right value for the regularization parameter is critical and can be challenging.\n",
    "Not Suitable for All Problems: For some types of data or models, regularization might not improve performance and could even worsen it.\n",
    "Q9. You are comparing the performance of two regression models using different evaluation metrics.\n",
    "Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better\n",
    "performer, and why? Are there any limitations to your choice of metric?\n",
    "Model Comparison:\n",
    "\n",
    "Model A (RMSE = 10) and Model B (MAE = 8) cannot be directly compared using RMSE and MAE because they measure different aspects of model performance. RMSE gives more weight to large errors, while MAE treats all errors equally.\n",
    "Q10. You are comparing the performance of two regularized linear models using different types of\n",
    "regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B\n",
    "uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the\n",
    "better performer, and why? Are there any trade-offs or limitations to your choice of regularization\n",
    "method?\n",
    "Comparison:\n",
    "\n",
    "Model A (Ridge Regularization, λ = 0.1) vs. Model B (Lasso Regularization, λ = 0.5):\n",
    "Ridge: Might perform better if you want to keep all features but reduce their impact.\n",
    "Lasso: Might perform better if you want to eliminate irrelevant features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
